\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{enumitem} 
% \usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{verbatim}
\usepackage{mathtools}
\usepackage[margin=1in]{geometry}
\usepackage{xcolor,graphicx}
\usepackage{macros}
\usepackage{animate}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{bbm}
\DeclareUnicodeCharacter{2212}{-}
\captionsetup{font=normalsize,labelfont={bf,sf}}

\title{Manifold Structure of High-Dimensional Data in Visual Perception}
\author{Liu Zhang}
\date{\today}

\begin{document}

\maketitle
This work builds on a long line of research aiming to develop more accurate mathematical and computational models of the visual system. It has recently been shown that feed-forward neural networks turn out to be inaccurate models for the brain. We focused on a related question that has not been investigated: how is the structure of recurrent and transformer neural networks related to that of neurobiological networks (in the mouse visual cortex)?

We first build the biological and artificial neuron tensors using experimental neural spiking data and numerical simulations on recurrent and transformer neural networks. Using tensor component analysis, we discover which groups of neurons respond similarly to which stimuli input. Since these groups are likely not independent, we use the non-linear dimensionality reduction method, diffusion maps, to infer a manifold of neurons. This manifold structure implies a functional network (represented by the discrete data graph underlying the continuous manifold) and thus reflects both the neural circuit connections and the neuronâ€™s role in those circuits. Comparing the manifold structures of biological and artificial neural networks allows us to make precise inferences about similarities and differences in their respective functional circuits. 
\end{document}