\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{enumitem} 
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{verbatim}
\usepackage{mathtools}
\usepackage[margin=1in]{geometry}
\usepackage{xcolor,graphicx}
\usepackage{macros}
\usepackage{animate}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{bbm}
\DeclareUnicodeCharacter{2212}{-}
\captionsetup{font=normalsize,labelfont={bf,sf}}

\title{Manifold Structure of High-Dimensional Data in Artificial and Biological Neural Networks}
\author{Liu Zhang}
\date{\today}

\begin{document}

\maketitle
This work builds on a long line of research aiming to develop more accurate mathematical and computational models of the visual system. It has recently been shown that feed-forward neural networks turn out to be inaccurate models for the brain. We focused on a related question that has not been investigated: how is the structure of recurrent and transformer neural networks related to that of neurobiological networks (in the mouse visual cortex)?

We first build the biological and artificial neuron tensors using experimental neural spiking data and numerical simulations on recurrent and transformer neural networks. Using tensor component analysis, we discover which groups of neurons respond similarly to which stimuli input. Using a dimensionality reduction method, tensor CP decomposition, we infer a manifold of neurons. This manifold structure implies a functional network represented by the discrete data graph underlying the continuous manifold and thus reflects both the neural circuit connections and the neuronâ€™s role in those circuits. For the first time, we find that CNN and ViT form disconnected clusters whereas RNN form a more continuous manifold.
\end{document}